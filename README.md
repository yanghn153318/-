# - 데이콘 한국어문장분류 경진대회
두 문장 간 관계 파악  
0: entailment, 1: constraction, 2: neutral  

Keywords: NLI, BERT, Pretrained model, Fine tuning


# - 자료 구조

한국어문장분류공모전:  
│  FolderStructure.txt  
│  
├─CODE  
│(&#6;)Ensemble.ipynb  
│       RoBERTa-large.ipynb  
│       TPU_BERT-base.ipynb  
│  
└─DATASET  
        result_roberta_large.csv  
        result_TPU.csv  
        sample_submission.csv  
        test_data.csv  
        train_data.csv  
        train_final.csv  
        
